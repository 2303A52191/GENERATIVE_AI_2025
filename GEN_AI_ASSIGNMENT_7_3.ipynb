{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/juoynCJqeDAMISRIuHwv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52191/GENERATIVE_AI_2025/blob/main/GEN_AI_ASSIGNMENT_7_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYgQDt2mDHLW",
        "outputId": "738d446e-3988-4dfb-b914-e6a462964f67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.2912 - loss: 0.7855 - val_accuracy: 0.3028 - val_loss: 0.7695\n",
            "Epoch 2/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.3534 - loss: 0.7212 - val_accuracy: 0.3119 - val_loss: 0.7526\n",
            "Epoch 3/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3204 - loss: 0.7207 - val_accuracy: 0.3211 - val_loss: 0.7386\n",
            "Epoch 4/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3385 - loss: 0.7169 - val_accuracy: 0.3119 - val_loss: 0.7264\n",
            "Epoch 5/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3272 - loss: 0.7071 - val_accuracy: 0.3028 - val_loss: 0.7159\n",
            "Epoch 6/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3721 - loss: 0.7114 - val_accuracy: 0.3028 - val_loss: 0.7063\n",
            "Epoch 7/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3480 - loss: 0.6714 - val_accuracy: 0.2936 - val_loss: 0.6979\n",
            "Epoch 8/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3590 - loss: 0.6662 - val_accuracy: 0.2844 - val_loss: 0.6897\n",
            "Epoch 9/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3740 - loss: 0.6688 - val_accuracy: 0.2936 - val_loss: 0.6822\n",
            "Epoch 10/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3329 - loss: 0.6661 - val_accuracy: 0.2752 - val_loss: 0.6753\n",
            "Epoch 11/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3652 - loss: 0.6591 - val_accuracy: 0.2844 - val_loss: 0.6686\n",
            "Epoch 12/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3413 - loss: 0.6474 - val_accuracy: 0.2752 - val_loss: 0.6618\n",
            "Epoch 13/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3437 - loss: 0.6322 - val_accuracy: 0.2752 - val_loss: 0.6557\n",
            "Epoch 14/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3833 - loss: 0.6390 - val_accuracy: 0.2752 - val_loss: 0.6495\n",
            "Epoch 15/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3785 - loss: 0.6325 - val_accuracy: 0.2844 - val_loss: 0.6438\n",
            "Epoch 16/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4191 - loss: 0.6206 - val_accuracy: 0.2936 - val_loss: 0.6384\n",
            "Epoch 17/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3992 - loss: 0.6175 - val_accuracy: 0.2844 - val_loss: 0.6331\n",
            "Epoch 18/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4089 - loss: 0.6058 - val_accuracy: 0.2844 - val_loss: 0.6280\n",
            "Epoch 19/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3480 - loss: 0.5989 - val_accuracy: 0.2752 - val_loss: 0.6230\n",
            "Epoch 20/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4052 - loss: 0.6045 - val_accuracy: 0.2752 - val_loss: 0.6181\n",
            "Epoch 21/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4226 - loss: 0.6110 - val_accuracy: 0.2752 - val_loss: 0.6134\n",
            "Epoch 22/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4496 - loss: 0.6080 - val_accuracy: 0.2752 - val_loss: 0.6082\n",
            "Epoch 23/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3773 - loss: 0.5729 - val_accuracy: 0.2752 - val_loss: 0.6037\n",
            "Epoch 24/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4520 - loss: 0.5836 - val_accuracy: 0.2752 - val_loss: 0.5990\n",
            "Epoch 25/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4323 - loss: 0.5732 - val_accuracy: 0.2752 - val_loss: 0.5946\n",
            "Epoch 26/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4213 - loss: 0.5664 - val_accuracy: 0.3028 - val_loss: 0.5900\n",
            "Epoch 27/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3863 - loss: 0.5708 - val_accuracy: 0.3028 - val_loss: 0.5858\n",
            "Epoch 28/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4552 - loss: 0.5608 - val_accuracy: 0.2844 - val_loss: 0.5815\n",
            "Epoch 29/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4300 - loss: 0.5636 - val_accuracy: 0.3028 - val_loss: 0.5773\n",
            "Epoch 30/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4542 - loss: 0.5628 - val_accuracy: 0.3028 - val_loss: 0.5731\n",
            "Epoch 31/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4583 - loss: 0.5536 - val_accuracy: 0.3028 - val_loss: 0.5690\n",
            "Epoch 32/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4680 - loss: 0.5544 - val_accuracy: 0.3028 - val_loss: 0.5649\n",
            "Epoch 33/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4433 - loss: 0.5506 - val_accuracy: 0.3028 - val_loss: 0.5609\n",
            "Epoch 34/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4165 - loss: 0.5440 - val_accuracy: 0.3028 - val_loss: 0.5571\n",
            "Epoch 35/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4186 - loss: 0.5257 - val_accuracy: 0.3119 - val_loss: 0.5531\n",
            "Epoch 36/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4273 - loss: 0.5275 - val_accuracy: 0.3211 - val_loss: 0.5492\n",
            "Epoch 37/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4333 - loss: 0.5079 - val_accuracy: 0.3211 - val_loss: 0.5453\n",
            "Epoch 38/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4086 - loss: 0.5254 - val_accuracy: 0.3211 - val_loss: 0.5415\n",
            "Epoch 39/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4658 - loss: 0.5171 - val_accuracy: 0.3119 - val_loss: 0.5376\n",
            "Epoch 40/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4390 - loss: 0.5193 - val_accuracy: 0.3119 - val_loss: 0.5337\n",
            "Epoch 41/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4449 - loss: 0.5072 - val_accuracy: 0.3119 - val_loss: 0.5297\n",
            "Epoch 42/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4344 - loss: 0.5062 - val_accuracy: 0.3119 - val_loss: 0.5258\n",
            "Epoch 43/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4333 - loss: 0.4934 - val_accuracy: 0.3119 - val_loss: 0.5219\n",
            "Epoch 44/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4432 - loss: 0.5098 - val_accuracy: 0.3211 - val_loss: 0.5181\n",
            "Epoch 45/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4599 - loss: 0.4956 - val_accuracy: 0.3211 - val_loss: 0.5144\n",
            "Epoch 46/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4406 - loss: 0.5205 - val_accuracy: 0.3211 - val_loss: 0.5105\n",
            "Epoch 47/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4307 - loss: 0.5091 - val_accuracy: 0.3211 - val_loss: 0.5066\n",
            "Epoch 48/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4405 - loss: 0.5223 - val_accuracy: 0.3303 - val_loss: 0.5028\n",
            "Epoch 49/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4184 - loss: 0.4544 - val_accuracy: 0.3394 - val_loss: 0.4991\n",
            "Epoch 50/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4349 - loss: 0.4602 - val_accuracy: 0.3394 - val_loss: 0.4953\n",
            "Epoch 51/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4474 - loss: 0.4685 - val_accuracy: 0.3394 - val_loss: 0.4915\n",
            "Epoch 52/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4513 - loss: 0.4752 - val_accuracy: 0.3303 - val_loss: 0.4877\n",
            "Epoch 53/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4619 - loss: 0.4721 - val_accuracy: 0.3303 - val_loss: 0.4837\n",
            "Epoch 54/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4156 - loss: 0.4603 - val_accuracy: 0.3303 - val_loss: 0.4800\n",
            "Epoch 55/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4851 - loss: 0.4670 - val_accuracy: 0.3303 - val_loss: 0.4761\n",
            "Epoch 56/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4555 - loss: 0.4593 - val_accuracy: 0.3303 - val_loss: 0.4724\n",
            "Epoch 57/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4487 - loss: 0.4363 - val_accuracy: 0.3303 - val_loss: 0.4686\n",
            "Epoch 58/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4191 - loss: 0.4634 - val_accuracy: 0.3303 - val_loss: 0.4647\n",
            "Epoch 59/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4399 - loss: 0.4170 - val_accuracy: 0.3394 - val_loss: 0.4609\n",
            "Epoch 60/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4069 - loss: 0.4583 - val_accuracy: 0.3394 - val_loss: 0.4573\n",
            "Epoch 61/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4475 - loss: 0.4343 - val_accuracy: 0.3394 - val_loss: 0.4535\n",
            "Epoch 62/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4343 - loss: 0.4199 - val_accuracy: 0.3394 - val_loss: 0.4494\n",
            "Epoch 63/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4470 - loss: 0.4437 - val_accuracy: 0.3394 - val_loss: 0.4455\n",
            "Epoch 64/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3758 - loss: 0.4159 - val_accuracy: 0.3394 - val_loss: 0.4416\n",
            "Epoch 65/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4244 - loss: 0.4140 - val_accuracy: 0.3394 - val_loss: 0.4380\n",
            "Epoch 66/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4257 - loss: 0.4257 - val_accuracy: 0.3394 - val_loss: 0.4340\n",
            "Epoch 67/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.4444 - loss: 0.4311 - val_accuracy: 0.3394 - val_loss: 0.4302\n",
            "Epoch 68/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4401 - loss: 0.3766 - val_accuracy: 0.3394 - val_loss: 0.4264\n",
            "Epoch 69/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4036 - loss: 0.3930 - val_accuracy: 0.3394 - val_loss: 0.4227\n",
            "Epoch 70/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4443 - loss: 0.4009 - val_accuracy: 0.3394 - val_loss: 0.4190\n",
            "Epoch 71/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4233 - loss: 0.3556 - val_accuracy: 0.3394 - val_loss: 0.4150\n",
            "Epoch 72/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4624 - loss: 0.4170 - val_accuracy: 0.3394 - val_loss: 0.4110\n",
            "Epoch 73/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4371 - loss: 0.3855 - val_accuracy: 0.3394 - val_loss: 0.4071\n",
            "Epoch 74/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4388 - loss: 0.3685 - val_accuracy: 0.3394 - val_loss: 0.4031\n",
            "Epoch 75/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4532 - loss: 0.3504 - val_accuracy: 0.3486 - val_loss: 0.3993\n",
            "Epoch 76/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4595 - loss: 0.3777 - val_accuracy: 0.3486 - val_loss: 0.3953\n",
            "Epoch 77/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4399 - loss: 0.3421 - val_accuracy: 0.3486 - val_loss: 0.3915\n",
            "Epoch 78/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4536 - loss: 0.3590 - val_accuracy: 0.3486 - val_loss: 0.3876\n",
            "Epoch 79/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4635 - loss: 0.3886 - val_accuracy: 0.3486 - val_loss: 0.3834\n",
            "Epoch 80/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4609 - loss: 0.4136 - val_accuracy: 0.3486 - val_loss: 0.3795\n",
            "Epoch 81/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4333 - loss: 0.3485 - val_accuracy: 0.3486 - val_loss: 0.3756\n",
            "Epoch 82/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4379 - loss: 0.3802 - val_accuracy: 0.3486 - val_loss: 0.3718\n",
            "Epoch 83/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4311 - loss: 0.3452 - val_accuracy: 0.3486 - val_loss: 0.3680\n",
            "Epoch 84/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.4245 - loss: 0.3226 - val_accuracy: 0.3486 - val_loss: 0.3642\n",
            "Epoch 85/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4184 - loss: 0.3166 - val_accuracy: 0.3486 - val_loss: 0.3601\n",
            "Epoch 86/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4586 - loss: 0.3494 - val_accuracy: 0.3486 - val_loss: 0.3561\n",
            "Epoch 87/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4000 - loss: 0.2927 - val_accuracy: 0.3486 - val_loss: 0.3521\n",
            "Epoch 88/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4207 - loss: 0.2854 - val_accuracy: 0.3486 - val_loss: 0.3480\n",
            "Epoch 89/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4404 - loss: 0.3074 - val_accuracy: 0.3486 - val_loss: 0.3439\n",
            "Epoch 90/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4650 - loss: 0.2522 - val_accuracy: 0.3486 - val_loss: 0.3400\n",
            "Epoch 91/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4738 - loss: 0.2827 - val_accuracy: 0.3486 - val_loss: 0.3363\n",
            "Epoch 92/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4622 - loss: 0.3534 - val_accuracy: 0.3486 - val_loss: 0.3323\n",
            "Epoch 93/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4423 - loss: 0.3362 - val_accuracy: 0.3486 - val_loss: 0.3282\n",
            "Epoch 94/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4420 - loss: 0.3092 - val_accuracy: 0.3486 - val_loss: 0.3242\n",
            "Epoch 95/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3936 - loss: 0.2850 - val_accuracy: 0.3486 - val_loss: 0.3201\n",
            "Epoch 96/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4373 - loss: 0.3300 - val_accuracy: 0.3486 - val_loss: 0.3162\n",
            "Epoch 97/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4433 - loss: 0.2460 - val_accuracy: 0.3486 - val_loss: 0.3120\n",
            "Epoch 98/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4485 - loss: 0.2722 - val_accuracy: 0.3486 - val_loss: 0.3080\n",
            "Epoch 99/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4001 - loss: 0.2860 - val_accuracy: 0.3486 - val_loss: 0.3040\n",
            "Epoch 100/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4416 - loss: 0.2944 - val_accuracy: 0.3486 - val_loss: 0.3001\n",
            "Epoch 101/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4510 - loss: 0.2517 - val_accuracy: 0.3486 - val_loss: 0.2961\n",
            "Epoch 102/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4104 - loss: 0.2986 - val_accuracy: 0.3486 - val_loss: 0.2920\n",
            "Epoch 103/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4353 - loss: 0.1926 - val_accuracy: 0.3486 - val_loss: 0.2882\n",
            "Epoch 104/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4723 - loss: 0.2383 - val_accuracy: 0.3486 - val_loss: 0.2841\n",
            "Epoch 105/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4693 - loss: 0.2600 - val_accuracy: 0.3486 - val_loss: 0.2803\n",
            "Epoch 106/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4453 - loss: 0.2466 - val_accuracy: 0.3486 - val_loss: 0.2763\n",
            "Epoch 107/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4631 - loss: 0.2131 - val_accuracy: 0.3486 - val_loss: 0.2723\n",
            "Epoch 108/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4562 - loss: 0.2684 - val_accuracy: 0.3486 - val_loss: 0.2682\n",
            "Epoch 109/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4563 - loss: 0.2019 - val_accuracy: 0.3486 - val_loss: 0.2642\n",
            "Epoch 110/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4522 - loss: 0.2657 - val_accuracy: 0.3394 - val_loss: 0.2601\n",
            "Epoch 111/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4606 - loss: 0.2191 - val_accuracy: 0.3394 - val_loss: 0.2561\n",
            "Epoch 112/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4604 - loss: 0.1924 - val_accuracy: 0.3394 - val_loss: 0.2520\n",
            "Epoch 113/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4002 - loss: 0.1455 - val_accuracy: 0.3394 - val_loss: 0.2477\n",
            "Epoch 114/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4347 - loss: 0.2356 - val_accuracy: 0.3394 - val_loss: 0.2438\n",
            "Epoch 115/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4220 - loss: 0.1501 - val_accuracy: 0.3394 - val_loss: 0.2397\n",
            "Epoch 116/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4144 - loss: 0.2034 - val_accuracy: 0.3394 - val_loss: 0.2358\n",
            "Epoch 117/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4340 - loss: 0.1916 - val_accuracy: 0.3394 - val_loss: 0.2315\n",
            "Epoch 118/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4421 - loss: 0.1894 - val_accuracy: 0.3394 - val_loss: 0.2273\n",
            "Epoch 119/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4416 - loss: 0.1755 - val_accuracy: 0.3394 - val_loss: 0.2232\n",
            "Epoch 120/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4337 - loss: 0.1734 - val_accuracy: 0.3394 - val_loss: 0.2190\n",
            "Epoch 121/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4083 - loss: 0.2586 - val_accuracy: 0.3394 - val_loss: 0.2145\n",
            "Epoch 122/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.4576 - loss: 0.1927 - val_accuracy: 0.3394 - val_loss: 0.2104\n",
            "Epoch 123/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.4358 - loss: 0.2479 - val_accuracy: 0.3394 - val_loss: 0.2064\n",
            "Epoch 124/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.4134 - loss: 0.1458 - val_accuracy: 0.3394 - val_loss: 0.2024\n",
            "Epoch 125/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.4561 - loss: 0.1249 - val_accuracy: 0.3394 - val_loss: 0.1982\n",
            "Epoch 126/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.3996 - loss: 0.1022 - val_accuracy: 0.3394 - val_loss: 0.1939\n",
            "Epoch 127/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4372 - loss: 0.1042 - val_accuracy: 0.3394 - val_loss: 0.1899\n",
            "Epoch 128/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.4406 - loss: 0.1926 - val_accuracy: 0.3394 - val_loss: 0.1858\n",
            "Epoch 129/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3823 - loss: 0.1710 - val_accuracy: 0.3394 - val_loss: 0.1816\n",
            "Epoch 130/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4424 - loss: 0.1099 - val_accuracy: 0.3394 - val_loss: 0.1774\n",
            "Epoch 131/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4462 - loss: 0.1573 - val_accuracy: 0.3394 - val_loss: 0.1734\n",
            "Epoch 132/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.4575 - loss: 0.1748 - val_accuracy: 0.3394 - val_loss: 0.1688\n",
            "Epoch 133/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.4428 - loss: 0.1177 - val_accuracy: 0.3486 - val_loss: 0.1646\n",
            "Epoch 134/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4402 - loss: 0.1106 - val_accuracy: 0.3486 - val_loss: 0.1604\n",
            "Epoch 135/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4562 - loss: 0.0824 - val_accuracy: 0.3486 - val_loss: 0.1564\n",
            "Epoch 136/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4270 - loss: 0.1750 - val_accuracy: 0.3486 - val_loss: 0.1523\n",
            "Epoch 137/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4364 - loss: 0.0420 - val_accuracy: 0.3486 - val_loss: 0.1482\n",
            "Epoch 138/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4549 - loss: 0.1258 - val_accuracy: 0.3486 - val_loss: 0.1438\n",
            "Epoch 139/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4492 - loss: 0.1504 - val_accuracy: 0.3486 - val_loss: 0.1399\n",
            "Epoch 140/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.4552 - loss: 0.0116 - val_accuracy: 0.3486 - val_loss: 0.1357\n",
            "Epoch 141/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4412 - loss: 0.1580 - val_accuracy: 0.3486 - val_loss: 0.1313\n",
            "Epoch 142/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4167 - loss: -2.8012e-04 - val_accuracy: 0.3486 - val_loss: 0.1273\n",
            "Epoch 143/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.4282 - loss: -0.0169 - val_accuracy: 0.3486 - val_loss: 0.1232\n",
            "Epoch 144/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4581 - loss: -0.1446 - val_accuracy: 0.3486 - val_loss: 0.1193\n",
            "Epoch 145/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4373 - loss: 0.0153 - val_accuracy: 0.3486 - val_loss: 0.1153\n",
            "Epoch 146/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4030 - loss: -0.0718 - val_accuracy: 0.3486 - val_loss: 0.1110\n",
            "Epoch 147/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4606 - loss: 0.0324 - val_accuracy: 0.3486 - val_loss: 0.1072\n",
            "Epoch 148/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4569 - loss: 0.1351 - val_accuracy: 0.3486 - val_loss: 0.1027\n",
            "Epoch 149/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4592 - loss: 0.0510 - val_accuracy: 0.3486 - val_loss: 0.0985\n",
            "Epoch 150/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4104 - loss: -0.0252 - val_accuracy: 0.3486 - val_loss: 0.0939\n",
            "Epoch 151/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4285 - loss: 0.0814 - val_accuracy: 0.3486 - val_loss: 0.0897\n",
            "Epoch 152/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4274 - loss: 0.0895 - val_accuracy: 0.3486 - val_loss: 0.0853\n",
            "Epoch 153/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4144 - loss: -0.0247 - val_accuracy: 0.3486 - val_loss: 0.0812\n",
            "Epoch 154/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4207 - loss: 0.0772 - val_accuracy: 0.3486 - val_loss: 0.0770\n",
            "Epoch 155/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4425 - loss: 0.0549 - val_accuracy: 0.3486 - val_loss: 0.0727\n",
            "Epoch 156/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4150 - loss: -0.0847 - val_accuracy: 0.3486 - val_loss: 0.0685\n",
            "Epoch 157/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4291 - loss: -0.1468 - val_accuracy: 0.3486 - val_loss: 0.0641\n",
            "Epoch 158/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4424 - loss: 0.0320 - val_accuracy: 0.3486 - val_loss: 0.0595\n",
            "Epoch 159/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4673 - loss: 0.0399 - val_accuracy: 0.3486 - val_loss: 0.0554\n",
            "Epoch 160/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4143 - loss: -0.0222 - val_accuracy: 0.3486 - val_loss: 0.0510\n",
            "Epoch 161/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4229 - loss: -0.1247 - val_accuracy: 0.3486 - val_loss: 0.0466\n",
            "Epoch 162/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4308 - loss: -0.0801 - val_accuracy: 0.3486 - val_loss: 0.0423\n",
            "Epoch 163/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4112 - loss: -0.1013 - val_accuracy: 0.3486 - val_loss: 0.0380\n",
            "Epoch 164/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4349 - loss: -0.0319 - val_accuracy: 0.3486 - val_loss: 0.0336\n",
            "Epoch 165/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4256 - loss: 0.0061 - val_accuracy: 0.3486 - val_loss: 0.0294\n",
            "Epoch 166/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4508 - loss: -0.1379 - val_accuracy: 0.3486 - val_loss: 0.0248\n",
            "Epoch 167/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4234 - loss: -0.1591 - val_accuracy: 0.3486 - val_loss: 0.0204\n",
            "Epoch 168/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4555 - loss: -0.0519 - val_accuracy: 0.3486 - val_loss: 0.0159\n",
            "Epoch 169/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4530 - loss: -0.1423 - val_accuracy: 0.3486 - val_loss: 0.0114\n",
            "Epoch 170/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4433 - loss: 0.0671 - val_accuracy: 0.3486 - val_loss: 0.0072\n",
            "Epoch 171/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4214 - loss: -0.0893 - val_accuracy: 0.3486 - val_loss: 0.0029\n",
            "Epoch 172/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4084 - loss: -0.1478 - val_accuracy: 0.3486 - val_loss: -0.0018\n",
            "Epoch 173/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4467 - loss: -0.0162 - val_accuracy: 0.3486 - val_loss: -0.0063\n",
            "Epoch 174/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4117 - loss: -0.0640 - val_accuracy: 0.3486 - val_loss: -0.0107\n",
            "Epoch 175/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4526 - loss: -0.1859 - val_accuracy: 0.3486 - val_loss: -0.0150\n",
            "Epoch 176/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4144 - loss: -0.0414 - val_accuracy: 0.3486 - val_loss: -0.0192\n",
            "Epoch 177/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4264 - loss: -0.0501 - val_accuracy: 0.3486 - val_loss: -0.0236\n",
            "Epoch 178/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4348 - loss: -0.1870 - val_accuracy: 0.3486 - val_loss: -0.0279\n",
            "Epoch 179/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4216 - loss: -0.0542 - val_accuracy: 0.3486 - val_loss: -0.0325\n",
            "Epoch 180/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4393 - loss: -0.0854 - val_accuracy: 0.3486 - val_loss: -0.0372\n",
            "Epoch 181/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4449 - loss: -0.1063 - val_accuracy: 0.3486 - val_loss: -0.0417\n",
            "Epoch 182/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3880 - loss: -0.1725 - val_accuracy: 0.3486 - val_loss: -0.0463\n",
            "Epoch 183/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4231 - loss: -0.1079 - val_accuracy: 0.3486 - val_loss: -0.0509\n",
            "Epoch 184/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4610 - loss: -0.1033 - val_accuracy: 0.3486 - val_loss: -0.0554\n",
            "Epoch 185/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4061 - loss: -0.2146 - val_accuracy: 0.3486 - val_loss: -0.0598\n",
            "Epoch 186/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4373 - loss: -0.2152 - val_accuracy: 0.3486 - val_loss: -0.0642\n",
            "Epoch 187/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4389 - loss: -0.0555 - val_accuracy: 0.3486 - val_loss: -0.0686\n",
            "Epoch 188/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3964 - loss: -0.3701 - val_accuracy: 0.3486 - val_loss: -0.0732\n",
            "Epoch 189/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4334 - loss: -0.1434 - val_accuracy: 0.3486 - val_loss: -0.0779\n",
            "Epoch 190/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4323 - loss: -0.2808 - val_accuracy: 0.3486 - val_loss: -0.0826\n",
            "Epoch 191/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4044 - loss: -0.0758 - val_accuracy: 0.3486 - val_loss: -0.0875\n",
            "Epoch 192/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4410 - loss: -0.2011 - val_accuracy: 0.3486 - val_loss: -0.0919\n",
            "Epoch 193/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4013 - loss: -0.1929 - val_accuracy: 0.3486 - val_loss: -0.0965\n",
            "Epoch 194/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4352 - loss: -0.3436 - val_accuracy: 0.3486 - val_loss: -0.1011\n",
            "Epoch 195/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4376 - loss: -0.3595 - val_accuracy: 0.3486 - val_loss: -0.1058\n",
            "Epoch 196/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4068 - loss: -0.2904 - val_accuracy: 0.3486 - val_loss: -0.1103\n",
            "Epoch 197/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4538 - loss: -0.2168 - val_accuracy: 0.3486 - val_loss: -0.1150\n",
            "Epoch 198/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4773 - loss: -0.2383 - val_accuracy: 0.3486 - val_loss: -0.1198\n",
            "Epoch 199/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4037 - loss: -0.1816 - val_accuracy: 0.3486 - val_loss: -0.1244\n",
            "Epoch 200/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4705 - loss: -0.3496 - val_accuracy: 0.3486 - val_loss: -0.1291\n",
            "Epoch 201/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4306 - loss: -0.2091 - val_accuracy: 0.3486 - val_loss: -0.1339\n",
            "Epoch 202/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4660 - loss: -0.2096 - val_accuracy: 0.3486 - val_loss: -0.1386\n",
            "Epoch 203/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4227 - loss: -0.1373 - val_accuracy: 0.3486 - val_loss: -0.1434\n",
            "Epoch 204/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4327 - loss: -0.2696 - val_accuracy: 0.3486 - val_loss: -0.1481\n",
            "Epoch 205/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4458 - loss: -0.5041 - val_accuracy: 0.3486 - val_loss: -0.1527\n",
            "Epoch 206/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4558 - loss: -0.4418 - val_accuracy: 0.3486 - val_loss: -0.1576\n",
            "Epoch 207/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4462 - loss: -0.3250 - val_accuracy: 0.3486 - val_loss: -0.1621\n",
            "Epoch 208/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4206 - loss: -0.5305 - val_accuracy: 0.3486 - val_loss: -0.1669\n",
            "Epoch 209/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3996 - loss: -0.4227 - val_accuracy: 0.3486 - val_loss: -0.1716\n",
            "Epoch 210/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4273 - loss: -0.4632 - val_accuracy: 0.3486 - val_loss: -0.1764\n",
            "Epoch 211/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4343 - loss: -0.3802 - val_accuracy: 0.3486 - val_loss: -0.1812\n",
            "Epoch 212/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4445 - loss: -0.2996 - val_accuracy: 0.3486 - val_loss: -0.1860\n",
            "Epoch 213/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4192 - loss: -0.3253 - val_accuracy: 0.3486 - val_loss: -0.1908\n",
            "Epoch 214/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4331 - loss: -0.3234 - val_accuracy: 0.3486 - val_loss: -0.1954\n",
            "Epoch 215/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4253 - loss: -0.2926 - val_accuracy: 0.3486 - val_loss: -0.2001\n",
            "Epoch 216/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4131 - loss: -0.4851 - val_accuracy: 0.3486 - val_loss: -0.2047\n",
            "Epoch 217/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4372 - loss: -0.3092 - val_accuracy: 0.3486 - val_loss: -0.2096\n",
            "Epoch 218/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4837 - loss: -0.5141 - val_accuracy: 0.3486 - val_loss: -0.2143\n",
            "Epoch 219/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4515 - loss: -0.3653 - val_accuracy: 0.3486 - val_loss: -0.2195\n",
            "Epoch 220/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4446 - loss: -0.3322 - val_accuracy: 0.3486 - val_loss: -0.2244\n",
            "Epoch 221/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4320 - loss: -0.4157 - val_accuracy: 0.3486 - val_loss: -0.2295\n",
            "Epoch 222/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4171 - loss: -0.2787 - val_accuracy: 0.3486 - val_loss: -0.2344\n",
            "Epoch 223/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4175 - loss: -0.5221 - val_accuracy: 0.3486 - val_loss: -0.2392\n",
            "Epoch 224/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4488 - loss: -0.4122 - val_accuracy: 0.3486 - val_loss: -0.2442\n",
            "Epoch 225/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4276 - loss: -0.2956 - val_accuracy: 0.3486 - val_loss: -0.2493\n",
            "Epoch 226/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4153 - loss: -0.4701 - val_accuracy: 0.3486 - val_loss: -0.2548\n",
            "Epoch 227/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4381 - loss: -0.4693 - val_accuracy: 0.3486 - val_loss: -0.2599\n",
            "Epoch 228/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4100 - loss: -0.5056 - val_accuracy: 0.3486 - val_loss: -0.2653\n",
            "Epoch 229/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4438 - loss: -0.5857 - val_accuracy: 0.3486 - val_loss: -0.2706\n",
            "Epoch 230/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4374 - loss: -0.3753 - val_accuracy: 0.3486 - val_loss: -0.2759\n",
            "Epoch 231/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3964 - loss: -0.4274 - val_accuracy: 0.3486 - val_loss: -0.2817\n",
            "Epoch 232/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4303 - loss: -0.5549 - val_accuracy: 0.3486 - val_loss: -0.2869\n",
            "Epoch 233/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4473 - loss: -0.4721 - val_accuracy: 0.3486 - val_loss: -0.2920\n",
            "Epoch 234/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4526 - loss: -0.3396 - val_accuracy: 0.3486 - val_loss: -0.2972\n",
            "Epoch 235/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4421 - loss: -0.4532 - val_accuracy: 0.3486 - val_loss: -0.3027\n",
            "Epoch 236/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4638 - loss: -0.3023 - val_accuracy: 0.3486 - val_loss: -0.3077\n",
            "Epoch 237/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4337 - loss: -0.4127 - val_accuracy: 0.3486 - val_loss: -0.3129\n",
            "Epoch 238/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4352 - loss: -0.5835 - val_accuracy: 0.3486 - val_loss: -0.3183\n",
            "Epoch 239/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4069 - loss: -0.5722 - val_accuracy: 0.3486 - val_loss: -0.3238\n",
            "Epoch 240/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4327 - loss: -0.4176 - val_accuracy: 0.3486 - val_loss: -0.3296\n",
            "Epoch 241/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4380 - loss: -0.4342 - val_accuracy: 0.3486 - val_loss: -0.3354\n",
            "Epoch 242/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4333 - loss: -0.6928 - val_accuracy: 0.3486 - val_loss: -0.3407\n",
            "Epoch 243/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4713 - loss: -0.6406 - val_accuracy: 0.3486 - val_loss: -0.3461\n",
            "Epoch 244/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4384 - loss: -0.5766 - val_accuracy: 0.3486 - val_loss: -0.3515\n",
            "Epoch 245/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4206 - loss: -0.5653 - val_accuracy: 0.3486 - val_loss: -0.3569\n",
            "Epoch 246/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4363 - loss: -0.5598 - val_accuracy: 0.3486 - val_loss: -0.3623\n",
            "Epoch 247/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4421 - loss: -0.6785 - val_accuracy: 0.3486 - val_loss: -0.3683\n",
            "Epoch 248/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4153 - loss: -0.7138 - val_accuracy: 0.3486 - val_loss: -0.3736\n",
            "Epoch 249/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4375 - loss: -0.8223 - val_accuracy: 0.3486 - val_loss: -0.3793\n",
            "Epoch 250/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4170 - loss: -0.3643 - val_accuracy: 0.3486 - val_loss: -0.3847\n",
            "Epoch 251/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4389 - loss: -0.4276 - val_accuracy: 0.3486 - val_loss: -0.3906\n",
            "Epoch 252/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4647 - loss: -0.6581 - val_accuracy: 0.3486 - val_loss: -0.3959\n",
            "Epoch 253/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4177 - loss: -0.6451 - val_accuracy: 0.3486 - val_loss: -0.4014\n",
            "Epoch 254/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4250 - loss: -0.4611 - val_accuracy: 0.3486 - val_loss: -0.4067\n",
            "Epoch 255/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4148 - loss: -0.5519 - val_accuracy: 0.3486 - val_loss: -0.4123\n",
            "Epoch 256/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4343 - loss: -0.8352 - val_accuracy: 0.3486 - val_loss: -0.4179\n",
            "Epoch 257/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4238 - loss: -0.5730 - val_accuracy: 0.3486 - val_loss: -0.4237\n",
            "Epoch 258/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4485 - loss: -0.5491 - val_accuracy: 0.3486 - val_loss: -0.4295\n",
            "Epoch 259/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4006 - loss: -0.6008 - val_accuracy: 0.3486 - val_loss: -0.4353\n",
            "Epoch 260/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4482 - loss: -0.5473 - val_accuracy: 0.3486 - val_loss: -0.4412\n",
            "Epoch 261/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4176 - loss: -0.5085 - val_accuracy: 0.3486 - val_loss: -0.4471\n",
            "Epoch 262/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4401 - loss: -0.5502 - val_accuracy: 0.3486 - val_loss: -0.4537\n",
            "Epoch 263/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4441 - loss: -0.6353 - val_accuracy: 0.3486 - val_loss: -0.4598\n",
            "Epoch 264/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4593 - loss: -0.7938 - val_accuracy: 0.3486 - val_loss: -0.4655\n",
            "Epoch 265/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4037 - loss: -0.8319 - val_accuracy: 0.3486 - val_loss: -0.4716\n",
            "Epoch 266/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4320 - loss: -0.8112 - val_accuracy: 0.3486 - val_loss: -0.4778\n",
            "Epoch 267/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4398 - loss: -0.9180 - val_accuracy: 0.3486 - val_loss: -0.4834\n",
            "Epoch 268/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4408 - loss: -0.9284 - val_accuracy: 0.3486 - val_loss: -0.4894\n",
            "Epoch 269/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4119 - loss: -0.3742 - val_accuracy: 0.3486 - val_loss: -0.4953\n",
            "Epoch 270/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4774 - loss: -0.3172 - val_accuracy: 0.3486 - val_loss: -0.5016\n",
            "Epoch 271/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.3921 - loss: -0.8024 - val_accuracy: 0.3486 - val_loss: -0.5081\n",
            "Epoch 272/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4270 - loss: -0.8832 - val_accuracy: 0.3486 - val_loss: -0.5140\n",
            "Epoch 273/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4604 - loss: -0.9827 - val_accuracy: 0.3486 - val_loss: -0.5204\n",
            "Epoch 274/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4367 - loss: -0.4913 - val_accuracy: 0.3486 - val_loss: -0.5264\n",
            "Epoch 275/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4283 - loss: -0.6781 - val_accuracy: 0.3486 - val_loss: -0.5320\n",
            "Epoch 276/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4247 - loss: -0.5962 - val_accuracy: 0.3486 - val_loss: -0.5383\n",
            "Epoch 277/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4462 - loss: -0.7698 - val_accuracy: 0.3486 - val_loss: -0.5444\n",
            "Epoch 278/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4409 - loss: -0.9935 - val_accuracy: 0.3486 - val_loss: -0.5508\n",
            "Epoch 279/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4279 - loss: -0.6361 - val_accuracy: 0.3486 - val_loss: -0.5571\n",
            "Epoch 280/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4422 - loss: -0.7329 - val_accuracy: 0.3486 - val_loss: -0.5638\n",
            "Epoch 281/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4125 - loss: -0.7866 - val_accuracy: 0.3578 - val_loss: -0.5702\n",
            "Epoch 282/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4712 - loss: -0.8050 - val_accuracy: 0.3578 - val_loss: -0.5766\n",
            "Epoch 283/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4364 - loss: -1.0378 - val_accuracy: 0.3578 - val_loss: -0.5828\n",
            "Epoch 284/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4372 - loss: -0.9009 - val_accuracy: 0.3578 - val_loss: -0.5889\n",
            "Epoch 285/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4310 - loss: -1.0627 - val_accuracy: 0.3578 - val_loss: -0.5954\n",
            "Epoch 286/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4317 - loss: -0.8812 - val_accuracy: 0.3578 - val_loss: -0.6017\n",
            "Epoch 287/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4363 - loss: -0.9406 - val_accuracy: 0.3578 - val_loss: -0.6079\n",
            "Epoch 288/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4308 - loss: -0.8580 - val_accuracy: 0.3578 - val_loss: -0.6144\n",
            "Epoch 289/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4219 - loss: -0.7964 - val_accuracy: 0.3578 - val_loss: -0.6210\n",
            "Epoch 290/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4415 - loss: -0.7466 - val_accuracy: 0.3578 - val_loss: -0.6276\n",
            "Epoch 291/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4211 - loss: -0.8435 - val_accuracy: 0.3578 - val_loss: -0.6338\n",
            "Epoch 292/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4018 - loss: -0.8378 - val_accuracy: 0.3578 - val_loss: -0.6409\n",
            "Epoch 293/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4694 - loss: -1.1597 - val_accuracy: 0.3578 - val_loss: -0.6478\n",
            "Epoch 294/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4172 - loss: -0.9587 - val_accuracy: 0.3578 - val_loss: -0.6548\n",
            "Epoch 295/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4777 - loss: -0.4786 - val_accuracy: 0.3578 - val_loss: -0.6611\n",
            "Epoch 296/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4428 - loss: -0.9553 - val_accuracy: 0.3578 - val_loss: -0.6677\n",
            "Epoch 297/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4245 - loss: -0.6975 - val_accuracy: 0.3578 - val_loss: -0.6740\n",
            "Epoch 298/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4269 - loss: -0.9565 - val_accuracy: 0.3578 - val_loss: -0.6806\n",
            "Epoch 299/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4586 - loss: -0.8219 - val_accuracy: 0.3578 - val_loss: -0.6870\n",
            "Epoch 300/300\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4236 - loss: -1.2422 - val_accuracy: 0.3578 - val_loss: -0.6942\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3358 - loss: -0.8892\n",
            "Test Accuracy: 0.3578\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Confusion Matrix:\n",
            " [[ 0 29  0]\n",
            " [ 0 39  0]\n",
            " [ 0 41  0]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        29\n",
            "           1       0.36      1.00      0.53        39\n",
            "           2       0.00      0.00      0.00        41\n",
            "\n",
            "    accuracy                           0.36       109\n",
            "   macro avg       0.12      0.33      0.18       109\n",
            "weighted avg       0.13      0.36      0.19       109\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "dataset_path = \"/content/Housing (1).csv\"\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    label_encoders[col] = LabelEncoder()\n",
        "    df[col] = label_encoders[col].fit_transform(df[col])\n",
        "\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(12, activation='swish', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(25, activation='swish'),\n",
        "    tf.keras.layers.Dense(15, activation='swish'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=300, batch_size=16, validation_data=(X_test, y_test))\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ]
    }
  ]
}